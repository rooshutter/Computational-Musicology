---
title: "Portfolio"
author: "Roos Hutter"
date: "2023-02-22"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    storyboard: true
    theme: 
      primary: "#304878"
      base_font: 
        google: Source Sans Pro
      
    
---

```{r setup, include=FALSE}
library(flexdashboard)
library(readr)
library(leaflet)
library(DT)
library(tidyverse)
library(lubridate)
library(plotly)
library(spotifyr)
library(Cairo)
library(compmus)
library(grid)
library(gridExtra)

otra <- readRDS(file = "data/otra-data.RDS")

knitr::opts_chunk$set(echo=FALSE)
```

Introduction {data-icon="music"}
=========================================

Row
-----------------------------------------------------------------------

### About the corpus and the analysis {data-width=700}

**The 'On the road (again)' corpus**  
If you take car rides with your family often, you probably know the struggle: chosing music to listen to together. My siblings and I have had this struggle for multiple years, until we came across the option on Spotify to make shared playlists. Now, we make one everytime we go on vacation together, to avoid any conflicts. 

For this computational musicological analysis I'm going to use one of the shared playlists. This playlist we used on vacation to Austria and it is called 'On the road (again)'. It contains different songs each of my sisters (Julia and Willemijn) and I (Roos). The focus for this portfolio will be on the differences and similarities between the songs each of us put in the playlist. 

**Expectations**  
Since they are my sisters, and I've known them all my life, I do have so speculations about the music tastes. However, I think it will still be worth looking into what these differences and similarities exactly are. 

I think it will be interesting to analyze the different genres of the songs. Additionally, the energy the songs have is an interesting aspect to look more into. I expect the artists and release dates of the songs to be different. Also, the similarities between the songs will be interesting to discover. Since this playlist was made to listen to during car rides, I expect the songs to have somewhat of a similar sound. Furthermore, my sisters and I do influence each others music taste a little bit. I hope to discover more about who influences who and in what way exactly.


### On the road (again) {data-width=300}
```{r}
#<iframe src="https://open.spotify.com/embed/playlist/6cZQQaJ0MsSHyUfGyuLgGK?utm_source=generator" width="99%" height="99%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

Row
-----------------------------------------------------------------------

### Amount of songs of Julia
```{r}

gauge(216, min = 0, max = 609, gaugeSectors(
  success = c(80, 609), warning = c(40, 79), danger = c(0, 39)
))

```
### Amount of songs of Willemijn
```{r}
gauge(52, min = 0, max = 609, gaugeSectors(
  success = c(80, 609), warning = c(40, 79), danger = c(0, 39)
))
```

### Amount of songs of Roos
```{r}
gauge(341, min = 0, max = 609, gaugeSectors(
  success = c(80, 609), warning = c(40, 79), danger = c(0, 39)
))
```

# Visualisations {.storyboard}

### Visualisation of the Acousticness {data-commentary-width=400}

```{r}
plot_acousticness <- readRDS(file = "data/plot_acousticness.RDS")

ggplotly(plot_acousticness)

```

***
**Terminology**  
This plot is a box plot about the acousticness of the songs added by Julia, Willemijn and Roos. Acousticness is a Spotify feature that ranges from 0.0 to 1.0. 1.0 represents high confidence that the track is acoustic.

**Explanation**  
You can clearly see that I have songs which are the most acoustic. It's interesting to see that Julia and Willemijn have similar acousticness.

### Visualisation of the Energy, Danceability and Mode {data-commentary-width=400}

```{r}
plot_evm <- readRDS(file = "data/plot_evm.RDS")

ggplotly(plot_evm)
```

***
**Terminology**  
This plot contains information about the energy, valence and mode of the songs added by Julia, Willemijn and Roos. Energy, valence and mode are all features from Spotify. Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. Valence is a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive, while tracks with low valence sound more negative. Mode indicates the modality (major or minor) of a track. Major is represented by 1 and minor is 0.

**Explanation**  
I think it's interesting that the energy of most songs are high. However you can see that Willemijn has the most songs with high energy, which I expected. Another interesting point is that Julia and Willemijn have similarities between energy, valence and mode, their plot looks kind of the same. However mine (Roos) looks very different, my songs are more spread out and have less energy. 

### Same songs



### Chromagrams of two versions of Crazy Little Thing Called Love {data-commentary-width=400}
```{r, out.width="40%"}
plot_chroma <- readRDS(file = "data/plot_chroma.RDS")
plot_chroma2 <- readRDS(file = "data/plot_chroma2.RDS")

subplot(plot_chroma, plot_chroma2, nrows = 2, margin = 0.04, heights = c(0.5, 0.5)) %>% layout(annotations = 
list(list(x = 0.5,  y = 1.0,  
          text = "Crazy Little Thing Called Love - Acoustic Version - Maroon 5",   
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE ),        list(x = 0.5, y = 0.46,  
          text = "Crazy Little Thing Called Love - Remastered 2011 - Queen",   
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE )))

```

--- 
**Terminology**  
These are two chromagrams of the same song 'Crazy Little Thing Called Love', however one is sung by Maroon 5 and the other by Queen. Chromagrams are representations of the pitch content during a song.

**Explanation**  
The one from Maroon 5 is added by me and the one from Queen is added by Julia. In the beginning, the Maroon 5 one is a lot in pitch class A and Queen is a lot in D. However, around 50 there is a similar pattern in pitch class E for both songs.

### Chroma vs Timbre of Acid Tears - Culi. {data-commentary-width=400}
```{r}
plot_at_chroma <- readRDS(file = "data/plot_at_chroma.RDS")
plot_at_timbre <- readRDS(file = "data/plot_at_timbre.RDS")

subplot(plot_at_chroma, plot_at_timbre) 
```
*** 
**Terminology**  
These plots show the chroma (left) and timbre (right) of the song 'Acid Tears' by 'Culi.'.

**Explanation**  
It was added by me. The song is pretty consistent till about 2.45. This is shown well in the chromagram, at 165 the chroma changes. Before this point it was mostly C#, and after it is higher and switches between A#, G#, F# and F. This switch is also seen in the timbre, at the end the c02 is present.

### Self-similarity matrices of Acid Tears - Culi. {data-commentary-width=400}
```{r}
bzt <- readRDS(file = "data/bzt.RDS")

bind_rows(
  bzt |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  bzt |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "", title="Self-similarity matrices")
```

***
These are self-similarity matrices of chroma and timbre of Acid Tears by Culi..

### Chordogram {data-commentary-width=400}
```{r}
queen_plot <- readRDS(file = "data/queen_plot.RDS")
phil_plot <- readRDS(file = "data/phil_plot.RDS")

subplot(queen_plot, phil_plot)

```

***
These are chordograms of Good Old-Fashioned Lover Boy by Queen (left) and Son of Man by Phil Collins (right)

### Tempogram {data-commentary-width=400}
```{r}
tempogram1 <- readRDS(file = "data/tempogram1.RDS")
tempogram2 <- readRDS(file = "data/tempogram2.RDS")
tempogram3 <- readRDS(file = "data/tempogram3.RDS")
tempogram4 <- readRDS(file = "data/tempogram4.RDS")


grid.arrange(tempogram1, tempogram2, tempogram3, tempogram4, ncol = 2)
```

***
These are four Fourier-based tempograms. A tempogram shows the tempo of a music piece over time. Viva La Vida by Coldplay and Good Old-Fashioned Lover Boy by Queen is added by Julia, King of Everything by Dominic Fike is added by Willemijn and my future by Billie Eilish is added by me (Roos). 

# Conclusion
